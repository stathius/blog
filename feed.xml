<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://stathius.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://stathius.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-03-17T09:47:48-05:00</updated><id>https://stathius.github.io/blog/feed.xml</id><title type="html">stathistics</title><subtitle>Machine learning and physics</subtitle><author><name>Stathi Fotiadis</name></author><entry><title type="html">Spatiotemporal data for pytorch in HDF5</title><link href="https://stathius.github.io/blog/2020/03/13/loading-spatiotemporal-data.html" rel="alternate" type="text/html" title="Spatiotemporal data for pytorch in HDF5" /><published>2020-03-13T00:00:00-05:00</published><updated>2020-03-13T00:00:00-05:00</updated><id>https://stathius.github.io/blog/2020/03/13/loading-spatiotemporal-data</id><content type="html" xml:base="https://stathius.github.io/blog/2020/03/13/loading-spatiotemporal-data.html">&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tl;dr
JPEG offers good compression for images but reading spatiotemporal data 
(image sequences) from disk can be slow. Images are also limited to 8bits per channel.  
HDF5 is faster, offers higher bit-depth but saves less space and requires some tweaking.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Spatiotemporal data consist of 2 or 3 spatial dimensions and there is also the dimension of time. They come in all sorts of flavors like video, traffic, temperature etc.  Personally I am interested in predicting physical dynamical systems.  In my last project, I was working with simulations of wave propagation. The data came in JPEG format, where each simulation would be a series of files. You can see an example of a data sequence below, and if you want to know a bit more about that work check this &lt;a href=&quot;https://arxiv.org/abs/2002.08981&quot;&gt;paper&lt;/a&gt; and &lt;a href=&quot;https://github.com/stathius/wave_propagation&quot;&gt;code&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/images/wavedata.jpg&quot; alt=&quot;&quot; title=&quot;An example of spatiotemporal data. One dimension is always time. Here, there are 2 spatial dimensions.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While I was using the data “as is” at the time, I started wondering whether JPEG files were the right format of storage. This was triggered because I noticed that during training, loading  data was the main bottleneck. I am using &lt;code class=&quot;highlighter-rouge&quot;&gt;pytorch&lt;/code&gt; and the provided &lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt; class does an extremely good job of pre-fetching data but increasing the number of workers didn’t seem to solve the problem, it even made it worse. There are also other concerns. The artefacts that JPEG introduces, while barely visible to the human eye, can also be quite important for your network. Another issue is normalization. Pixel values are in the 0-255 range. This means that the normalization needs to be known before hand but this is not always possible and might need to clipping or loss of “dynamic range”.&lt;/p&gt;

&lt;h2 id=&quot;data-formats&quot;&gt;Data formats&lt;/h2&gt;

&lt;p&gt;In the pre-&lt;code class=&quot;highlighter-rouge&quot;&gt;dataloader&lt;/code&gt; era the right format for data storage in deep learning was not obvious. One natural choice is storing image files in JPEG files. JPEG offers a significant compression over raw image data. This is also applicable to short videos, which after all are just sequences of images. The downside is that loading image files one by one takes long if you load many of them at once. Python has various libraries that can deal with loading images like &lt;code class=&quot;highlighter-rouge&quot;&gt;pillow&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Another popular way of storing images and videos is Hierarchical Data Format (HDF5). It a nutshell, HDF5 is good for big datasets with hierarchical structure. It only offers generic compression like GZIP and LZF. In &lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt; the &lt;a href=&quot;https://www.h5py.org/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;h5py&lt;/code&gt;&lt;/a&gt; library offers support for HDF5.&lt;/p&gt;

&lt;h2 id=&quot;speed-comparison&quot;&gt;Speed comparison&lt;/h2&gt;

&lt;p&gt;Saving snapshots in JPEG is straighforward but HDF5 has its quirks. There are a couple of variable that play a big role on the read/write speed of the dataset: chunking, compression, filesize.&lt;/p&gt;

&lt;p&gt;All datasets are comprised of 3000 datapoints, where each datapoint is a sequence of $100$ frames and each frame is a $184 \times 184$ array. A batch contains 10 randomly chosen datapoints ($10\times 100\times 184\times 184$). To compare the different data formats, I fetch 10 batches, so 100 datapoints in total, and report the time it takes &lt;em&gt;per datapoint&lt;/em&gt;. I also compare the time for 1,2,4 and 8 workers. For reference, all tests were conducted on a system equipped with a mid-range quad-core &lt;code class=&quot;highlighter-rouge&quot;&gt;i-7&lt;/code&gt; and a decent SSD.&lt;/p&gt;

&lt;p&gt;Here’s a summary of the results and following some analysis.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Format&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Chunks&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Compression&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Size&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time - 1 worker&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2 workers&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;4 workers&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;8 workers&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;JPEG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;2.4G&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.173&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.123&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.085&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.079&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Auto&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;LZF&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;19G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.449&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.413&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.812&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manual&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;LZF&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.041&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.022&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.013&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.013&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manual&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GZIP&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;12G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.067&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.035&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.022&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.019&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- | HDF5     | Auto     | LZF           | 2.1G           |             1.688 |       0.977 |       0.695 |       0.517 | --&gt;
&lt;!-- | HDF5     | Manual   | LZF           | 2.6G           |             0.051 |       0.027 |       0.016 |       0.015 | --&gt;

&lt;h3 id=&quot;correct-chunking-in-hdf-very-important&quot;&gt;Correct chunking in HDF very important&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://support.hdfgroup.org/HDF5/doc/Advanced/Chunking/index.html&quot;&gt;Chunking&lt;/a&gt; is a very important concept in HDF. I used two different methods, the first is auto-chunking. With this setting it takes 1.02 seconds with 4 workers to fetch a datapoint, which is slow. I set the chunk equal to the size of a datapoint ($100\times 184\times 184$ ).&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hdf5_store = h5py.File(filename, &quot;w&quot;)
images = hdf5_store.create_dataset('images', (num_datapoints,100,184,184), chunks=(1, 100, 184, 184), compression='gzip')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This made it dramatically faster and only took 0.013 seconds to fetch a datapoint, a 78x speed-up! If you have structured data and you know how much you’ll be fetching each time make sure to use that knowledge to your benefit.&lt;/p&gt;

&lt;h3 id=&quot;hdf5-with-correct-chunking-is-faster-than-jpeg&quot;&gt;HDF5 with correct chunking is faster than JPEG&lt;/h3&gt;

&lt;p&gt;JPEG might be more straightforward to use than HDF5 but it’s also slower. It takes 0.085 second on average for a JPEG-based dataloader to bring a datapoint. On the other hand, HDF5 only needs 0.013 seconds, more than 6.5x faster.&lt;/p&gt;

&lt;h3 id=&quot;compression&quot;&gt;Compression&lt;/h3&gt;

&lt;p&gt;HDF allows three types of compression: LZF, GZIP and SZIP. For GZIP you can adjust the compression strength from 1 to 9, where 1 is the least compression. JPEG also compresses images using the DCT encoding. JPEG is by far the best compression for this dataset, taking only 2.4GB. Probably because the dataset has a lot of constant intensity regions that JPEG is good with. HDF5 the  takes much more space, GZIP and correct chunking help a bit but only manage to reduce the size to 12G. In terms of speed HDF5 with LZF compression and manual chunking is the fastest. HDF5+GZIP is second fastest, so if disk space is a concern it’s worth considering.&lt;/p&gt;

&lt;h3 id=&quot;hdf-file-size&quot;&gt;HDF File size&lt;/h3&gt;

&lt;p&gt;I was also wondering if packing more datapoints in one file plays any role in the read speed of HDF5 files. The results in the table below. Apparently, if you do your chunking correct, bigger files are as fast as smaller ones, if not faster.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Format&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Chunks&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Datapoint&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Size&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time - 1 worker&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2 workers&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;4 workers&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;8 workers&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Auto&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3000&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;19G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.449&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.413&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.812&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Auto&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2.1G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.688&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.977&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.695&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.517&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manual&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3000&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.041&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.022&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.013&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.013&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HDF5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Manual&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2.6G&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.051&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.027&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.016&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.015&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;increasing-number-of-workers-has-limitations&quot;&gt;Increasing number of workers has limitations&lt;/h3&gt;

&lt;p&gt;Increasing the number of workers works well up to a certain extent. The speed-up is sublinear, using 4 instead of 1 worker is not 4x faster but rather 2.5-3x. Additionally, in most cases, using more than 4 workers does not provide any further gains.&lt;/p&gt;

&lt;h2 id=&quot;hdf5-vs-jpeg&quot;&gt;HDF5 vs JPEG&lt;/h2&gt;

&lt;p&gt;Pros&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Whole dataset in one file (important for staging)&lt;/li&gt;
  &lt;li&gt;Various compression schemes&lt;/li&gt;
  &lt;li&gt;Pretty fast if tweaked properly&lt;/li&gt;
  &lt;li&gt;Raw data with “unlimited” range&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Suboptimal compression for natural images/video&lt;/li&gt;
  &lt;li&gt;Need to fiddle with chunking&lt;/li&gt;
  &lt;li&gt;Learning curve for API&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Stathi Fotiadis</name></author><summary type="html">tl;dr JPEG offers good compression for images but reading spatiotemporal data (image sequences) from disk can be slow. Images are also limited to 8bits per channel. HDF5 is faster, offers higher bit-depth but saves less space and requires some tweaking.</summary></entry></feed>